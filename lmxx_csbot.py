import os
import logging
import datetime
import pytz
import random
from openai import OpenAI
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_API_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_CHAT_ID = os.getenv("CHAT_ID")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
ai_client = OpenAI(api_key=OPENAI_API_KEY)

# í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
KST = pytz.timezone("Asia/Seoul")

# ë¡œê·¸ ë””ë ‰í„°ë¦¬ ì„¤ì • (CS & ìµœì‹  IT ì£¼ì œ í¬í•¨)
LOG_DIR = "tech_logs"
os.makedirs(LOG_DIR, exist_ok=True)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)

# í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ
TELEGRAM_MESSAGE_LIMIT = 4096

CS_TOPICS = (
    "Operating Systems and Process Management",
    "Data Structures",
    "Algorithm Design",
    "Computer Networks and Protocols",
    "Databases and SQL Optimization",
    "Software Engineering Principles",
    "Compiler Design and Programming Languages",
    "Cybersecurity Fundamentals",
    "Cloud Computing and Distributed Systems",
    "Artificial Intelligence",
    "Deep Learning",
    "Machine Learning",
    "Data Science",
    "Blockchain",
    "Decentralized Finance (DeFi)",
    "Quantum Computing",
    "Cryptography",
    "Big Data Analytics and Data Engineering",
    "IoT (Internet of Things)",
    "Edge Computing",
    "Augmented Reality (AR)",
    "Virtual Reality (VR)"
)

def split_message(text, limit=TELEGRAM_MESSAGE_LIMIT):
    """ ë©”ì‹œì§€ë¥¼ Telegram ìµœëŒ€ ê¸¸ì´ (4096ì) ì´í•˜ë¡œ ë¶„í•  """
    messages = []
    while len(text) > limit:
        split_index = text.rfind("\n", 0, limit)  # ìµœëŒ€ ê¸¸ì´ë¥¼ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ì¤„ë°”ê¿ˆ ë‹¨ìœ„ë¡œ ìë¦„
        if split_index == -1:  # ì¤„ë°”ê¿ˆ ì—†ìœ¼ë©´ ê°•ì œ ìë¦„
            split_index = limit
        messages.append(text[:split_index])
        text = text[split_index:].strip()
    messages.append(text)
    return messages

def generate_tech_content():
    selected_topic = random.choice(CS_TOPICS)

    prompt = (
        f"You are an expert in Computer Science. Choose a **key subtopic** related to the following major topic: {selected_topic}. "
        f"Ensure the subtopic is **highly relevant and commonly discussed** within this field.\n\n"
        f"Provide a structured explanation including the following sections:\n\n"
        
        f"1. **Introduction** - Briefly introduce {selected_topic} and its significance.\n"
        f"2. **Core Concepts** - Explain the fundamental principles and key areas of {selected_topic}.\n"
        f"3. **Key Subtopic** - Select and analyze a crucial subtopic within {selected_topic}. Provide a detailed explanation covering:\n"
        f"   - **Definition**: What it is and why it matters.\n"
        f"   - **Mechanism**: How it works, including key components and workflow.\n"
        f"   - **Challenges & Limitations**: Potential issues and drawbacks.\n"
        f"   - **Comparison**: If applicable, compare it with alternative approaches.\n"
        f"   - **Future Trends**: How this subtopic is evolving in modern computing.\n\n"
        
        f"4. **Real-World Applications** - List major fields where {selected_topic} and the selected subtopic are applied, with a one-line explanation for each:\n"
        f"   - **Industry/Technology 1**: [One-sentence explanation]\n"
        f"   - **Industry/Technology 2**: [One-sentence explanation]\n"
        f"   - **Industry/Technology 3**: [One-sentence explanation]\n\n"
        
        f"Ensure the explanation is clear, well-structured, and suitable for those with a basic understanding of Computer Science."
    )


    try:
        response = ai_client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=1500  # ìµœëŒ€ í† í°ì„ ì¤„ì—¬ì„œ ë„ˆë¬´ ê¸´ ì‘ë‹µ ë°©ì§€
        )
        tech_content = response.choices[0].message.content.strip()

        # ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ë°˜ íŒŒì¼ ì €ì¥
        today_date = datetime.datetime.now(KST).strftime("%Y-%m-%d")
        file_path = os.path.join(LOG_DIR, f"{today_date}_tech_content.txt")

        with open(file_path, "w", encoding="utf-8") as file:
            file.write(tech_content)

        logging.info(f"Tech content saved to {file_path}.")
        return f"ğŸ“˜ [Topic: {selected_topic}]\n\n{tech_content}"

    except Exception as e:
        logging.error(f"OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "âš ï¸ An error occurred while generating the technology content."

# /start ëª…ë ¹ì–´ ì²˜ë¦¬
async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    topics_message = "**ğŸ“Œ Available CS & Tech Topics:**\n\n" + "\n".join(f"- {topic}" for topic in CS_TOPICS)
    
    welcome_message = (
        "ğŸ‘‹ Welcome! Use the /tech command to get a detailed explanation on a trending technology topic.\n\n"
        "ğŸ”¹ Here are the topics you can explore:\n\n"
        f"{topics_message}\n\n"
        "ğŸ“ A subtopic within these fields will be automatically selected for a detailed explanation."
    )

    await update.message.reply_text(welcome_message, parse_mode="Markdown")


# /tech ëª…ë ¹ì–´ë¡œ ê¸°ìˆ  ì½˜í…ì¸  ì œê³µ (ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ ì ìš©)
async def tech_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("Generating an in-depth tech explanation, please wait...")
    tech_content = generate_tech_content()

    messages = split_message(tech_content)
    for msg in messages:
        await update.message.reply_text(msg)  # ê¸¸ì´ ì œí•œì„ ì¤€ìˆ˜í•˜ë©° ë¶„í• ëœ ë©”ì‹œì§€ ì „ì†¡

# ë§¤ì¼ ìë™ìœ¼ë¡œ ê¸°ìˆ  ì½˜í…ì¸  ì „ì†¡ (ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ ì ìš©)
async def daily_tech_update(context: ContextTypes.DEFAULT_TYPE):
    tech_content = generate_tech_content()
    messages = split_message(tech_content)

    for msg in messages:
        await context.bot.send_message(chat_id=TELEGRAM_CHAT_ID, text=msg)

# JobQueue ì„¤ì •
async def setup_job_queue(application):
    job_queue = application.job_queue
    kst_time = datetime.time(hour=9, minute=0, second=0, tzinfo=KST)
    job_queue.run_daily(daily_tech_update, time=kst_time)

# ë©”ì¸ í•¨ìˆ˜
def main():
    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).post_init(setup_job_queue).build()

    # ëª…ë ¹ì–´ í•¸ë“¤ëŸ¬ ë“±ë¡
    app.add_handler(CommandHandler("start", start_command))
    app.add_handler(CommandHandler("tech", tech_command))

    # ë´‡ ì‹¤í–‰
    app.run_polling()

if __name__ == '__main__':
    main()
